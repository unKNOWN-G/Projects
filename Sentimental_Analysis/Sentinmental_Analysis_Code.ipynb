{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "preceding-saturday",
   "metadata": {},
   "source": [
    "## Header Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protective-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import layers, regularizers\n",
    "from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D,Dropout\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop = stopwords.words('english')\n",
    "stop.extend(['@', '.', '#', 'user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-precipitation",
   "metadata": {},
   "source": [
    "## Loading Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fewer-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_add = \"./Data/IMDB Dataset.csv\"\n",
    "train_data = pd.read_csv(train_data_add)\n",
    "one_hot = []\n",
    "for i in range(len(train_data[\"sentiment\"])):\n",
    "    if(train_data.iloc[i,1]==\"positive\"):\n",
    "        one_hot.append(1)\n",
    "    else:\n",
    "        one_hot.append(0)\n",
    "train_data[\"encoded\"] = one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-wages",
   "metadata": {},
   "source": [
    "## Checking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "joined-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "                                              review sentiment  encoded\n",
      "0  One of the other reviewers has mentioned that ...  positive        1\n",
      "1  A wonderful little production. <br /><br />The...  positive        1\n",
      "2  I thought this was a wonderful way to spend ti...  positive        1\n",
      "Length of Test data =  50000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data\")\n",
    "print(train_data.head(3))\n",
    "print(\"Length of Test data = \", len(train_data))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "obvious-bonus",
   "metadata": {},
   "source": [
    "\n",
    "            Pre-processing of data\n",
    "    0) Making Every tweet to lowercase\n",
    "    1) Tokenization\n",
    "    2) Stop Word \n",
    "    3) Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "waiting-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment  encoded\n",
      "0  one of the other reviewers has mentioned that ...  positive        1\n",
      "1  a wonderful little production. <br /><br />the...  positive        1\n",
      "2  i thought this was a wonderful way to spend ti...  positive        1\n",
      "3  basically there's a family where a little boy ...  negative        0\n",
      "4  petter mattei's \"love in the time of money\" is...  positive        1\n"
     ]
    }
   ],
   "source": [
    "# Converting to Lower Case\n",
    "for i in range(len(train_data)):\n",
    "    train_data.iloc[i, 0] = train_data.iloc[i, 0].lower()\n",
    "print(train_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-career",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "consistent-identity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Tokenizing          :  ['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', 'you', \"'ll\", 'be', 'hooked', '.', 'they', 'are', 'right', ',', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', ',', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', '.', 'trust', 'me', ',', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', '.', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', ',', 'sex', 'or', 'violence', '.', 'its', 'is', 'hardcore', ',', 'in', 'the', 'classic', 'use', 'of', 'the', 'word.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary', '.', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', ',', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', ',', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', '.', 'em', 'city', 'is', 'home', 'to', 'many', '..', 'aryans', ',', 'muslims', ',', 'gangstas', ',', 'latinos', ',', 'christians', ',', 'italians', ',', 'irish', 'and', 'more', '....', 'so', 'scuffles', ',', 'death', 'stares', ',', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'would', \"n't\", 'dare', '.', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', ',', 'forget', 'charm', ',', 'forget', 'romance', '...', 'oz', 'does', \"n't\", 'mess', 'around', '.', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', ',', 'i', 'could', \"n't\", 'say', 'i', 'was', 'ready', 'for', 'it', ',', 'but', 'as', 'i', 'watched', 'more', ',', 'i', 'developed', 'a', 'taste', 'for', 'oz', ',', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', '.', 'not', 'just', 'violence', ',', 'but', 'injustice', '(', 'crooked', 'guards', 'who', \"'ll\", 'be', 'sold', 'out', 'for', 'a', 'nickel', ',', 'inmates', 'who', \"'ll\", 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', ',', 'well', 'mannered', ',', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', ')', 'watching', 'oz', ',', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', '....', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for i in range(len(train_data)):\n",
    "    tokens.append(nltk.word_tokenize(train_data.iloc[i, 0]))\n",
    "print(\"After Tokenizing          : \", tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-understanding",
   "metadata": {},
   "source": [
    "## Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "extreme-addiction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Removing Stop Words :  ['one', 'reviewers', 'mentioned', 'watching', '1', 'oz', 'episode', \"'ll\", 'hooked', 'right', ',', 'exactly', 'happened', 'me.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'first', 'thing', 'struck', 'oz', 'brutality', 'unflinching', 'scenes', 'violence', ',', 'set', 'right', 'word', 'go', 'trust', ',', 'show', 'faint', 'hearted', 'timid', 'show', 'pulls', 'punches', 'regards', 'drugs', ',', 'sex', 'violence', 'hardcore', ',', 'classic', 'use', 'word.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'called', 'oz', 'nickname', 'given', 'oswald', 'maximum', 'security', 'state', 'penitentary', 'focuses', 'mainly', 'emerald', 'city', ',', 'experimental', 'section', 'prison', 'cells', 'glass', 'fronts', 'face', 'inwards', ',', 'privacy', 'high', 'agenda', 'em', 'city', 'home', 'many', '..', 'aryans', ',', 'muslims', ',', 'gangstas', ',', 'latinos', ',', 'christians', ',', 'italians', ',', 'irish', '....', 'scuffles', ',', 'death', 'stares', ',', 'dodgy', 'dealings', 'shady', 'agreements', 'never', 'far', 'away.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'would', 'say', 'main', 'appeal', 'show', 'due', 'fact', 'goes', 'shows', 'would', \"n't\", 'dare', 'forget', 'pretty', 'pictures', 'painted', 'mainstream', 'audiences', ',', 'forget', 'charm', ',', 'forget', 'romance', '...', 'oz', \"n't\", 'mess', 'around', 'first', 'episode', 'ever', 'saw', 'struck', 'nasty', 'surreal', ',', 'could', \"n't\", 'say', 'ready', ',', 'watched', ',', 'developed', 'taste', 'oz', ',', 'got', 'accustomed', 'high', 'levels', 'graphic', 'violence', 'violence', ',', 'injustice', '(', 'crooked', 'guards', \"'ll\", 'sold', 'nickel', ',', 'inmates', \"'ll\", 'kill', 'order', 'get', 'away', ',', 'well', 'mannered', ',', 'middle', 'class', 'inmates', 'turned', 'prison', 'bitches', 'due', 'lack', 'street', 'skills', 'prison', 'experience', ')', 'watching', 'oz', ',', 'may', 'become', 'comfortable', 'uncomfortable', 'viewing', '....', 'thats', 'get', 'touch', 'darker', 'side']\n"
     ]
    }
   ],
   "source": [
    "filtered_tokens = []\n",
    "for i in range(len(tokens)):\n",
    "    filtered_tokens.append([word for word in tokens[i] if word not in stop])\n",
    "print(\"After Removing Stop Words : \", filtered_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-circuit",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "previous-utilization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Lemmatization       :  ['one', 'reviewer', 'mentioned', 'watching', '1', 'oz', 'episode', \"'ll\", 'hooked', 'right', ',', 'exactly', 'happened', 'me.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'first', 'thing', 'struck', 'oz', 'brutality', 'unflinching', 'scene', 'violence', ',', 'set', 'right', 'word', 'go', 'trust', ',', 'show', 'faint', 'hearted', 'timid', 'show', 'pull', 'punch', 'regard', 'drug', ',', 'sex', 'violence', 'hardcore', ',', 'classic', 'use', 'word.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'called', 'oz', 'nickname', 'given', 'oswald', 'maximum', 'security', 'state', 'penitentary', 'focus', 'mainly', 'emerald', 'city', ',', 'experimental', 'section', 'prison', 'cell', 'glass', 'front', 'face', 'inwards', ',', 'privacy', 'high', 'agenda', 'em', 'city', 'home', 'many', '..', 'aryan', ',', 'muslim', ',', 'gangsta', ',', 'latino', ',', 'christian', ',', 'italian', ',', 'irish', '....', 'scuffle', ',', 'death', 'stare', ',', 'dodgy', 'dealing', 'shady', 'agreement', 'never', 'far', 'away.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'would', 'say', 'main', 'appeal', 'show', 'due', 'fact', 'go', 'show', 'would', \"n't\", 'dare', 'forget', 'pretty', 'picture', 'painted', 'mainstream', 'audience', ',', 'forget', 'charm', ',', 'forget', 'romance', '...', 'oz', \"n't\", 'mess', 'around', 'first', 'episode', 'ever', 'saw', 'struck', 'nasty', 'surreal', ',', 'could', \"n't\", 'say', 'ready', ',', 'watched', ',', 'developed', 'taste', 'oz', ',', 'got', 'accustomed', 'high', 'level', 'graphic', 'violence', 'violence', ',', 'injustice', '(', 'crooked', 'guard', \"'ll\", 'sold', 'nickel', ',', 'inmate', \"'ll\", 'kill', 'order', 'get', 'away', ',', 'well', 'mannered', ',', 'middle', 'class', 'inmate', 'turned', 'prison', 'bitch', 'due', 'lack', 'street', 'skill', 'prison', 'experience', ')', 'watching', 'oz', ',', 'may', 'become', 'comfortable', 'uncomfortable', 'viewing', '....', 'thats', 'get', 'touch', 'darker', 'side']\n"
     ]
    }
   ],
   "source": [
    "lemmatizers = []\n",
    "for i in range(len(filtered_tokens)):\n",
    "    lemmatizers.append([lemmatizer.lemmatize(word) for word in filtered_tokens[i]])\n",
    "print(\"After Lemmatization       : \", lemmatizers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "grand-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " The next step currently is converting these words into numbers based on occurances and padding with zeros for length  \n",
    "\"\"\"\n",
    "a=0\n",
    "for i in range(len(lemmatizers)):\n",
    "    a=max(a,len(lemmatizers[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aggressive-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words=[]\n",
    "for i in range(len(lemmatizers)):\n",
    "    total_words.extend(lemmatizers[i])\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    num_words = total_words,\n",
    "    filters = '\"#$%&()*+-/:;<=>@[\\]^_`{|}~'\n",
    ")\n",
    "tokenizer.fit_on_texts(lemmatizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "wicked-drinking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1706\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-patrol",
   "metadata": {},
   "source": [
    "## Finding Highest frequency of words and creating the int dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "minor-valuation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lemmatizers_to_int = Counter(total_words)\n",
    "total_word_count = len(total_words)\n",
    "sorted_order = lemmatizers_to_int.most_common(total_word_count)\n",
    "print(lemmatizers_to_int)\n",
    "vocab_to_index = {w: i+1 for i, (w, c) in enumerate(sorted_order)}\n",
    "print(vocab_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-planner",
   "metadata": {},
   "source": [
    "## Encoding to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "combined-category",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_encoded_reviews = []\n",
    "for i in range(len(lemmatizers)):\n",
    "    num_encoded_reviews.append([vocab_to_index[word] for word in lemmatizers[i]])\n",
    "print(num_encoded_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-voluntary",
   "metadata": {},
   "source": [
    "## Padding and truncating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accredited-niagara",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ...   149  7456   361]\n",
      " [    0     0     0 ...  7458 15346  9704]\n",
      " [    0     0     0 ...     0    33  3159]\n",
      " ...\n",
      " [    0     0     0 ...  7208    44    82]\n",
      " [    0     0     0 ...  1490  1491   491]\n",
      " [    0     0     0 ...     0   121   131]]\n"
     ]
    }
   ],
   "source": [
    "padded_reviews = pad_sequences(num_encoded_reviews, maxlen=90)\n",
    "print(padded_reviews)\n",
    "y_train = np.asarray(np.array(train_data.iloc[:,1])).astype('float32').reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "amino-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "ping=[]\n",
    "for i in range(len(num_encoded_reviews)):\n",
    "    ping.append((num_encoded_reviews[i],y_train[i]))\n",
    "random.shuffle(ping)\n",
    "\n",
    "training_set = ping[:20000]\n",
    "testing_set = ping[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "derived-orlando",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "800/800 [==============================] - 12s 12ms/step - loss: 0.2612 - accuracy: 0.0722 - val_loss: 0.1287 - val_accuracy: 0.0695\n",
      "WARNING:tensorflow:Can save best model only with val-accuracy available, skipping.\n",
      "Epoch 2/50\n",
      "560/800 [====================>.........] - ETA: 2s - loss: 0.0940 - accuracy: 0.0697"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-52162d4f7602>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Our vectorized labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_reviews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\Sentimental_Analysis\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Sentimental_Analysis\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Sentimental_Analysis\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Sentimental_Analysis\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Sentimental_Analysis\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Sentimental_Analysis\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Sentimental_Analysis\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now we are ready to train our model through LSTM network\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(len(vocab_to_index)+1,output_dim = 10,input_length = 90))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(layers.LSTM(90))\n",
    "model.add(layers.Dense(1,activation='softmax', input_shape=(50,)))\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(\"best_mode1_11-02-2021.hdf5\",monitor='val-accuracy',save_best_only = True, save_weights_only= False)\n",
    "\n",
    "# Our vectorized labels\n",
    "model.fit(np.array(padded_reviews), y_train, validation_split=0.2 , epochs=50, callbacks=[checkpoint1], verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(len(train_data.iloc[:,1])):\n",
    "    if(train_data.iloc[i,1]==1):\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "count,len(train_data.iloc[:,1])-count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data.iloc[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim = len(vocab_to_index)+1, output_dim = 256, input_length = 70))\n",
    "model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(1, activation = 'softmax'))\n",
    "model_lstm.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 8\n",
    "X_train= np.array(padded_reviews)\n",
    "y_train = np.array(train_data.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_lstm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split = 0.1,\n",
    "    epochs = 8,\n",
    "    batch_size = 512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-punishment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-river",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
